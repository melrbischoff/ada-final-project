{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f202aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0d78fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spotify():\n",
    "    '''\n",
    "    Class to handle hitting spotify API to get music features\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, \n",
    "                 client_id=None, \n",
    "                 client_secret=None):\n",
    "        \n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        \n",
    "        self.get_access_token()\n",
    "        \n",
    "        \n",
    "    def get_access_token(self):\n",
    "        ## Example use:\n",
    "        ## spotify_instance = Spotify(CLIENT_ID, CLIENT_SECRET)\n",
    "        ## spotify_instance.get_access_token()\n",
    "        \n",
    "        secret_bytes = bytes(('{}:{}'.format(self.client_id, self.client_secret)),'utf-8')\n",
    "        secret_enc = base64.b64encode(secret_bytes).decode('utf-8')\n",
    "        \n",
    "        data = {'grant_type': 'client_credentials'}\n",
    "        headers = {'Authorization': 'Basic {}'.format(secret_enc)}\n",
    "        url = 'https://accounts.spotify.com/api/token'\n",
    "        r = requests.post(url, headers=headers, data=data)\n",
    "        \n",
    "        self.access_token = r.json()['access_token']\n",
    "    \n",
    "    def lookup_spotify_id(self, id_list):\n",
    "        '''\n",
    "        this takes in ISRC and returns ISRC to Spotify ID map\n",
    "        '''\n",
    "        df = pd.DataFrame([])\n",
    "        bad_ids = []\n",
    "        for i in id_list:\n",
    "            r = requests.get(f'https://api.spotify.com/v1/search?type=track&q=isrc:{i}',\n",
    "                             headers = {'Authorization': 'Bearer ' + self.access_token})\n",
    "            while r.status_code == 429:\n",
    "                retry_secs = int(r.headers['Retry-After'])\n",
    "                print('sleeping for {}'.format(retry_secs))\n",
    "                time.sleep(retry_secs)\n",
    "            try:\n",
    "                spotify_id = r.json()['tracks']['items'][0]['id']\n",
    "                row = {'isrc': str(i), 'spotify_id': spotify_id}\n",
    "                df = df.append(row, ignore_index = True)\n",
    "            except:\n",
    "#                 print(f'id issue {len(bad_ids) + 1}')\n",
    "                row = {'isrc': str(i), 'spotify_id': None}\n",
    "                df = df.append(row, ignore_index = True)\n",
    "                bad_ids.append(i)\n",
    "        return df\n",
    "    \n",
    "    def lookup_album_id(self, id_list):\n",
    "        '''\n",
    "        this takes in UPC and returns UPC to Spotify Album ID\n",
    "        '''\n",
    "        df = pd.DataFrame([])\n",
    "        bad_ids = []\n",
    "        for i in id_list:\n",
    "            r = requests.get(f'https://api.spotify.com/v1/search?type=album&q=upc:{i}',\n",
    "                             headers = {'Authorization': 'Bearer ' + self.access_token})\n",
    "            while r.status_code == 429:\n",
    "                retry_secs = int(r.headers['Retry-After'])\n",
    "                print('sleeping for {}'.format(retry_secs))\n",
    "                time.sleep(retry_secs)\n",
    "            try:\n",
    "                spotify_id = r.json()['albums']['items'][0]['id']\n",
    "                row = {'upc': str(i), 'spotify_album_id': spotify_id}\n",
    "                df = df.append(row, ignore_index = True)\n",
    "            except:\n",
    "#                 print(f'id issue {len(bad_ids) + 1}')\n",
    "                row = {'upc': str(i), 'spotify_album_id': None}\n",
    "                df = df.append(row, ignore_index = True)\n",
    "                bad_ids.append(i)\n",
    "        return df\n",
    "    \n",
    "    def group_ids(self, list_of_ids, bucket_size=100):\n",
    "        list_of_ids = pd.DataFrame(list_of_ids, columns=['id'])\n",
    "        list_of_ids['bucket'] = np.floor(np.arange(len(list_of_ids)) / bucket_size)\n",
    "        \n",
    "        gpd_ids = list_of_ids.groupby('bucket')['id'].apply(lambda x: ','.join(x))\n",
    "        \n",
    "        return gpd_ids\n",
    "\n",
    "    def get_audio_features(self, id_list, bucket_size=100):\n",
    "        \n",
    "        gpd_ids = self.group_ids(id_list, bucket_size)\n",
    "        col_list = ['acousticness', 'liveness', 'instrumentalness', \n",
    "                    'analysis_url', 'uri', 'time_signature', 'loudness', \n",
    "                    'speechiness', 'duration_ms', 'danceability', 'mode', \n",
    "                    'id', 'energy', 'key', 'track_href', \n",
    "                    'valence', 'type', 'tempo']\n",
    "        \n",
    "        df = []\n",
    "        \n",
    "        for x in gpd_ids.values:\n",
    "            r = requests.get('https://api.spotify.com/v1/audio-features?ids={}'.format(x), \n",
    "                             headers = {'Authorization': 'Bearer ' + self.access_token})\n",
    "            while r.status_code == 429:\n",
    "                retry_secs = int(r.headers['Retry-After'])\n",
    "                time.sleep(retry_secs)\n",
    "            \n",
    "            audio_features = r.json()['audio_features']\n",
    "            audio_features = [i for i in audio_features if i]\n",
    "            \n",
    "            for row in audio_features:\n",
    "                for c in col_list:\n",
    "                    if c not in row:\n",
    "                        row[c] = None\n",
    "                df.append(row)\n",
    "    \n",
    "        return pd.DataFrame(df)\n",
    "    \n",
    "    def get_tracks(self, id_list, bucket_size=50):\n",
    "        \n",
    "        gpd_ids = self.group_ids(id_list, bucket_size)\n",
    "        col_list = ['popularity', 'name', 'uri', 'external_urls', 'type', 'duration_ms', 'external_ids',\n",
    "                    'album', 'explicit', 'id', 'preview_url', 'track_number', 'available_markets', 'is_local', \n",
    "                    'artists', 'href', 'disc_number']\n",
    "        \n",
    "        track_df = []\n",
    "        \n",
    "        for x in gpd_ids.values:\n",
    "            r = requests.get('https://api.spotify.com/v1/tracks?ids={}'.format(x),\n",
    "                             headers = {'Authorization': 'Bearer ' + self.access_token})\n",
    "            \n",
    "            while r.status_code == 429:\n",
    "                retry_secs = int(r.headers['Retry-After'])\n",
    "                time.sleep(retry_secs)\n",
    "                  \n",
    "            tracks = r.json()['tracks']\n",
    "            tracks = [i for i in tracks if i]\n",
    "            \n",
    "            for row in tracks:\n",
    "                for c in col_list:\n",
    "                    if c not in row:\n",
    "                        row[c] = None\n",
    "                track_df.append(row)\n",
    "        \n",
    "        final_track_df = pd.DataFrame(track_df)\n",
    "        \n",
    "        final_track_df['release_date'] = pd.json_normalize(final_track_df['album'])['release_date']\n",
    "        final_track_df['album_id'] = pd.json_normalize(final_track_df['album'])['id']\n",
    "        \n",
    "        return final_track_df[['id','popularity','album_id','release_date']]\n",
    "\n",
    "    def get_albums(self, id_list, bucket_size=20):\n",
    "        \n",
    "        gpd_ids = self.group_ids(id_list, bucket_size)\n",
    "        col_list = ['id','release_date', 'release_date_precision','total_tracks','type']\n",
    "        \n",
    "        album_df = []\n",
    "        \n",
    "        for x in gpd_ids.values:\n",
    "            r = requests.get('https://api.spotify.com/v1/albums?ids={}'.format(x),\n",
    "                             headers = {'Authorization': 'Bearer ' + self.access_token})\n",
    "            \n",
    "            while r.status_code == 429:\n",
    "                retry_secs = int(r.headers['Retry-After'])\n",
    "                time.sleep(retry_secs)\n",
    "                  \n",
    "            albums = r.json()['albums']\n",
    "            albums = [i for i in albums if i]\n",
    "            \n",
    "            for a in albums:\n",
    "                df_row = {x: a[x] for x in col_list}\n",
    "                album_df.append(df_row)\n",
    "                \n",
    "        final_album_df = pd.DataFrame(album_df)\n",
    "        return final_album_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b157177",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'ae17fb14354d4d98a442007563fafab9'\n",
    "client_secret = 'cb9e3752f07f4cfc9685c9369fd4b11c'\n",
    "\n",
    "sp = Spotify(client_id,client_secret)\n",
    "sp.get_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "664079a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'data/'\n",
    "dataset_path = r'data/mri_full_data.csv'\n",
    "\n",
    "music_data = pd.read_csv(dataset_path)\n",
    "music_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "music_data['Display Upc'] = music_data['Display Upc'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ade8e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrc_ids = list(music_data[~music_data.ISRC.isna()].ISRC.unique())\n",
    "upc_ids = list(music_data[~music_data['Display Upc'].isna()]['Display Upc'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f5e43de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrc_to_spotify_id = sp.lookup_spotify_id(isrc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "979e5c64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upc_to_spotify_album_id = sp.lookup_album_id(upc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "10b4c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "isrc_to_spotify_id.to_csv(os.path.join(data_path, 'isrc_to_spotify_id.csv'))\n",
    "upc_to_spotify_album_id.to_csv(os.path.join(data_path, 'upc_to_spotify_album_id.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "513fa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_ids = (isrc_to_spotify_id[~(isrc_to_spotify_id.spotify_id.isna())].spotify_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e5a3f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_audio_feats = sp.get_audio_features(spotify_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b4dc5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_audio_feats.to_csv(os.path.join(data_path, 'track_audio_feats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bdd07db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_album_ids = list(\n",
    "    upc_to_spotify_album_id[\n",
    "        ~(upc_to_spotify_album_id.spotify_album_id.isna())\n",
    "    ].spotify_album_id.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7eb12a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_information = sp.get_albums(spotify_album_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d95100d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_information.to_csv(os.path.join(data_path, 'album_information.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693e754",
   "metadata": {},
   "source": [
    "# join & write all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "30d14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data_merged_spotify = music_data.merge(\n",
    "    isrc_to_spotify_id,\n",
    "    how = 'left',\n",
    "    left_on = 'ISRC',\n",
    "    right_on = 'isrc'\n",
    ").merge(\n",
    "    upc_to_spotify_album_id,\n",
    "    how = 'left',\n",
    "    left_on = 'Display Upc',\n",
    "    right_on = 'upc'\n",
    ").merge(\n",
    "    track_audio_feats,\n",
    "    how = 'left',\n",
    "    left_on = 'spotify_id',\n",
    "    right_on = 'id'\n",
    ").drop(\n",
    "    ['id', 'uri','track_href','analysis_url','type'],\n",
    "    axis = 1\n",
    ").merge(\n",
    "    album_information,\n",
    "    how = 'left',\n",
    "    left_on = 'spotify_album_id',\n",
    "    right_on = 'id'\n",
    ").drop(\n",
    "    ['id', 'isrc', 'upc'],\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dddc832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data_merged_spotify['type'] = np.where(\n",
    "    (music_data_merged_spotify.type.isna()) & ~(music_data_merged_spotify.spotify_id.isna()),\n",
    "    'track',\n",
    "    music_data_merged_spotify.type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6fd7dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data_merged_spotify.to_csv(os.path.join(data_path, 'music_data_merged_spotify.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d184666",
   "metadata": {},
   "source": [
    "# joining stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cccf05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704716 out of 4757930 rows have spotify information (98.9%)\n"
     ]
    }
   ],
   "source": [
    "len_match = len(music_data_merged_spotify[~(music_data_merged_spotify.type.isna())])\n",
    "len_df = len(music_data_merged_spotify)\n",
    "print (f'{len_match} out of {len_df} rows have spotify information ({np.round((len_match/len_df) * 100, 1)}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
